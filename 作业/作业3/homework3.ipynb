{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([1., 4., 1.])\n",
    "y2 = np.array([1., 2., 2.])\n",
    "y3 = np.array([-1., 0., -2.])\n",
    "y4 = np.array([-1., -1., -1.])\n",
    "\n",
    "class perceptron:\n",
    "    def __init__(self) -> None:\n",
    "        self.a = None\n",
    "    def single_fit(\n",
    "            self, \n",
    "            initial_value,\n",
    "            train_set, \n",
    "            eta:float, \n",
    "            theta:float=0., \n",
    "            max_iteration:int=1000\n",
    "    ) -> None:\n",
    "        self.a = np.copy(initial_value)\n",
    "        print('initial weight:', self.a)\n",
    "        for i in range(max_iteration):\n",
    "            print('epoch:', i + 1)\n",
    "            flag = True\n",
    "            for y in train_set:\n",
    "                if np.dot(self.a, y) <= theta:\n",
    "                    print('error in sample:', y, end='\\t\\t')\n",
    "                    flag = False\n",
    "                    self.a += eta * y\n",
    "                    print('weight after correction:', self.a)\n",
    "            if flag:\n",
    "                print('successfully fit the training set')\n",
    "                print('the final weight is:', self.a)\n",
    "                return\n",
    "        print('failed to fit the training set in given iteration times')\n",
    "    def batch_fit(\n",
    "            self, \n",
    "            initial_value,\n",
    "            train_set, \n",
    "            eta:float, \n",
    "            theta:float=0., \n",
    "            max_iteration:int=1000\n",
    "    ) -> None:\n",
    "        self.a = np.copy(initial_value)\n",
    "        print('initial weight:', self.a)\n",
    "        for i in range(max_iteration):\n",
    "            print('epoch:', i + 1)\n",
    "            error_set = []\n",
    "            for y in train_set:\n",
    "                if np.dot(self.a, y) <= theta:\n",
    "                    error_set.append(y)\n",
    "            if len(error_set) == 0:\n",
    "                print('successfully fit the training set')\n",
    "                print('the final weight is:', self.a)\n",
    "                return\n",
    "            for y in error_set:\n",
    "                print('error in sample:', y)\n",
    "            self.a += eta * np.sum(error_set, axis=0)\n",
    "            print('weight after correction', self.a)\n",
    "        print('failed to fit the training set in given iteration times')\n",
    "\n",
    "\n",
    "single_model = perceptron()\n",
    "batch_model = perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weight: [0. 0. 0.]\n",
      "epoch: 1\n",
      "error in sample: [1. 4. 1.]\t\tweight after correction: [1. 4. 1.]\n",
      "error in sample: [-1.  0. -2.]\t\tweight after correction: [ 0.  4. -1.]\n",
      "error in sample: [-1. -1. -1.]\t\tweight after correction: [-1.  3. -2.]\n",
      "epoch: 2\n",
      "error in sample: [-1. -1. -1.]\t\tweight after correction: [-2.  2. -3.]\n",
      "epoch: 3\n",
      "error in sample: [1. 2. 2.]\t\tweight after correction: [-1.  4. -1.]\n",
      "error in sample: [-1. -1. -1.]\t\tweight after correction: [-2.  3. -2.]\n",
      "epoch: 4\n",
      "error in sample: [1. 2. 2.]\t\tweight after correction: [-1.  5.  0.]\n",
      "error in sample: [-1. -1. -1.]\t\tweight after correction: [-2.  4. -1.]\n",
      "epoch: 5\n",
      "error in sample: [-1. -1. -1.]\t\tweight after correction: [-3.  3. -2.]\n",
      "epoch: 6\n",
      "error in sample: [1. 2. 2.]\t\tweight after correction: [-2.  5.  0.]\n",
      "error in sample: [-1. -1. -1.]\t\tweight after correction: [-3.  4. -1.]\n",
      "epoch: 7\n",
      "error in sample: [-1. -1. -1.]\t\tweight after correction: [-4.  3. -2.]\n",
      "epoch: 8\n",
      "error in sample: [1. 2. 2.]\t\tweight after correction: [-3.  5.  0.]\n",
      "error in sample: [-1. -1. -1.]\t\tweight after correction: [-4.  4. -1.]\n",
      "epoch: 9\n",
      "successfully fit the training set\n",
      "the final weight is: [-4.  4. -1.]\n"
     ]
    }
   ],
   "source": [
    "single_model.single_fit(\n",
    "    initial_value=np.array([0., 0., 0.]),\n",
    "    train_set=[y1, y2, y3, y4],\n",
    "    eta=1.,\n",
    "    theta=0.,\n",
    "    max_iteration=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weight: [-3. -1.  1.]\n",
      "epoch: 1\n",
      "error in sample: [1. 4. 1.]\n",
      "error in sample: [1. 2. 2.]\n",
      "weight after correction [-2.   2.   2.5]\n",
      "epoch: 2\n",
      "error in sample: [-1.  0. -2.]\n",
      "error in sample: [-1. -1. -1.]\n",
      "weight after correction [-3.   1.5  1. ]\n",
      "epoch: 3\n",
      "error in sample: [-1. -1. -1.]\n",
      "weight after correction [-3.5  1.   0.5]\n",
      "epoch: 4\n",
      "error in sample: [1. 2. 2.]\n",
      "weight after correction [-3.   2.   1.5]\n",
      "epoch: 5\n",
      "error in sample: [-1.  0. -2.]\n",
      "error in sample: [-1. -1. -1.]\n",
      "weight after correction [-4.   1.5  0. ]\n",
      "epoch: 6\n",
      "error in sample: [1. 2. 2.]\n",
      "weight after correction [-3.5  2.5  1. ]\n",
      "epoch: 7\n",
      "error in sample: [-1. -1. -1.]\n",
      "weight after correction [-4.   2.   0.5]\n",
      "epoch: 8\n",
      "successfully fit the training set\n",
      "the final weight is: [-4.   2.   0.5]\n"
     ]
    }
   ],
   "source": [
    "batch_model.batch_fit(\n",
    "    initial_value=np.array([-3., -1., 1.]),\n",
    "    train_set=[y1, y2, y3, y4],\n",
    "    eta=0.5,\n",
    "    theta=0.5,\n",
    "    max_iteration=1000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([2., 2., 3.])\n",
    "x2 = np.array([4., 0., 3.])\n",
    "x3 = np.array([3., 1., -1.])\n",
    "m = np.average([x1, x2, x3], axis=0)\n",
    "S = np.sum(\n",
    "    [np.outer((x - m), (x - m)) \n",
    "    for x in [x1, x2, x3]], axis=0\n",
    ")\n",
    "w, e = np.linalg.eig(S)\n",
    "reduced_x = [\n",
    "    np.dot(e[:, -1], (x - m))\n",
    "    for x in [x1, x2, x3]\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([1., 3.])\n",
    "x2 = np.array([3., 7.])\n",
    "x3 = np.array([2., 2.])\n",
    "x4 = np.array([-1., -3.])\n",
    "x5 = np.array([-3., -7.])\n",
    "m1 = np.average([x1, x2, x3], axis=0)\n",
    "m2 = np.average([x4, x5], axis=0)\n",
    "s1 = np.sum(\n",
    "    [np.outer((x - m1), (x - m1))\n",
    "     for x in [x1, x2, x3]], axis=0\n",
    ")\n",
    "s2 = np.sum(\n",
    "    [np.outer((x - m2), (x - m2))\n",
    "     for x in [x4, x5]], axis=0\n",
    ")\n",
    "sw = s1 + s2\n",
    "sb = np.outer((m1 - m2), (m1 - m2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
