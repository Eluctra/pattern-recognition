{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 概率密度估计的基本方法\n",
    "<br /><br />\n",
    "    * 一个样本点$\\boldsymbol{x}$落在区域$\\mathcal{R}$中的概率为\n",
    "    $$\n",
    "    P = \\int_{\\mathcal{R}} p(\\boldsymbol{x}) d\\boldsymbol{x}\n",
    "    $$\n",
    "    * 在独立抽取的$n$个样本中，落在区域$\\mathcal{R}$中的数量\n",
    "    $$\n",
    "    k \\sim b(n,\\ P)\n",
    "    $$\n",
    "    * $k$的数学期望\n",
    "    $$\n",
    "    \\mathcal{E}(k) = nP\n",
    "    $$\n",
    "    * 当区域$\\mathcal{R}$取得足够小时，区域$\\mathcal{R}$中一点$\\boldsymbol{x}$处的概率密度满足\n",
    "    $$\n",
    "    \\mathcal{E}(k) = nP = n \\int_{\\mathcal{R}} p(\\tau) d\\tau \\approx n p(\\boldsymbol{x}) V\n",
    "    $$\n",
    "    * 由此得到$\\boldsymbol{x}$处的概率密度的估计\n",
    "    $$\n",
    "    \\hat{p}(\\boldsymbol{x}) \\approx \\frac{P}{V} \\approx \\frac{k/n}{V}\n",
    "    $$\n",
    "    * 为了保证估计方法的收敛性，分别需要\n",
    "    <br /><br />\n",
    "        * 保证区域$\\mathcal{R}$收缩得足够小\n",
    "        $$\n",
    "        \\lim_{n \\to \\infty} V_{n} =  0\n",
    "        $$\n",
    "        * 在概率密度不为0的前提下保证频数足够多\n",
    "        $$\n",
    "        \\lim_{n \\to \\infty} k_{n} = \\infty\n",
    "        $$\n",
    "        * 在区域收缩得足够小时保证频率也足够小\n",
    "        $$\n",
    "        \\lim_{n \\to \\infty} k_{n} / n = 0\n",
    "        $$\n",
    "    * 分别可以通过固定区域大小序列$V_{n}$或频数序列$k_{n}$的方式来获取满足以上条件的估计序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\mathrm{Parzen}$窗方法\n",
    "<br /><br />\n",
    "    * 固定一个合法的超立方体区域序列\n",
    "    $$\n",
    "    V_{n} = h_{n}^{d}\n",
    "    $$\n",
    "    * 定义窗函数（在标准超立方体内为1，否则为0）\n",
    "    $$\n",
    "    \\varphi(\\boldsymbol{u}) = \\mathbb{I}\\left( |u_{j}| \\le \\frac{1}{2} \\right);\\ j = 1,\\ 2,\\ \\cdots,\\ d\n",
    "    $$\n",
    "    * 落在超立方体区域中的样本频数\n",
    "    $$\n",
    "    k_{n} = \\sum_{i = 1}^{n} \\varphi \\left( \\frac{\\boldsymbol{x} - \\boldsymbol{x}_{i}}{h_{n}} \\right)\n",
    "    $$\n",
    "    * 估计得到的概率密度\n",
    "    $$\n",
    "    p_{n}(\\boldsymbol{x}) = \\frac{1}{nV_{n}} \\sum_{i = 1}^{n} \\varphi \\left( \\frac{\\boldsymbol{x} - \\boldsymbol{x}_{i}}{h_{n}} \\right)\n",
    "    $$\n",
    "    * 合法的概率密度要求\n",
    "    $$\n",
    "    \\begin{gather*}\n",
    "    p_{n}(\\boldsymbol{x}) \\ge 0\\ \\Leftrightarrow\\ \\varphi(\\boldsymbol{u}) \\ge 0 \\\\ \\\\\n",
    "    \\int_{\\mathbb{R}^d} p_{n}(\\boldsymbol{x}) d\\boldsymbol{x} = 1\\ \\Leftrightarrow\\ \\int_{\\mathbb{R}^d} \\varphi(\\boldsymbol{u}) d\\boldsymbol{u} = 1\n",
    "    \\end{gather*}\n",
    "    $$\n",
    "    * 满足上述要求的窗函数同样可以用于概率密度的估计，例如常用的高斯窗\n",
    "    $$\n",
    "    \\varphi(\\boldsymbol{u}) = \\varphi \\left( \\frac{\\boldsymbol{x} - \\boldsymbol{x}_{i}}{h_{n}} \\right) = N(0,\\ \\boldsymbol{\\Sigma})\n",
    "    $$\n",
    "    * 定义影响因子如下\n",
    "    $$\n",
    "    \\delta_{n}(\\boldsymbol{x}) = \\frac{1}{V_{n}} \\varphi \\left( \\frac{\\boldsymbol{x}}{h_{n}} \\right)\n",
    "    $$\n",
    "    * 估计概率密度可以重写为\n",
    "    $$\n",
    "    p_{n}(\\boldsymbol{x}) = \\frac{1}{n} \\sum_{i = 1}^{n} \\delta_{n}(\\boldsymbol{x} - \\boldsymbol{x}_{i})\n",
    "    $$\n",
    "    * 在窗宽$h_{n}$过大时，影响因子过于平滑，导致估计产生散焦；在窗宽$h_{n}$过小时，影响因子过于陡峭，导致估计充满噪声\n",
    "    <br /><br />\n",
    "    * $\\mathrm{Parzen}$窗估计的收敛性\n",
    "    <br /><br />\n",
    "        * 为了证明$\\mathrm{Parzen}$窗方法能够在样本数量趋于无穷时收敛到真实值，等价于证明\n",
    "        $$\n",
    "        \\begin{gather*}\n",
    "        \\lim_{n \\to \\infty} \\mathcal{E} p_{n}(\\boldsymbol{x}) = p(\\boldsymbol{x}) \\\\ \\\\\n",
    "        \\lim_{n \\to \\infty} \\mathcal{D} p_{n}(\\boldsymbol{x}) = 0\n",
    "        \\end{gather*}\n",
    "        $$\n",
    "        * 考虑估计得到的概率密度$p_{n}(\\boldsymbol{x})$的在训练集样本$\\boldsymbol{x}_{i}$上的期望\n",
    "        $$\n",
    "        \\begin{align*}\n",
    "        \\mathcal{E} p_{n}(\\boldsymbol{x}) &= \\frac{1}{nV_{n}} \\sum_{i = 1}^{n} \\mathcal{E} \\left[ \\varphi \n",
    "        \\left( \\frac{\\boldsymbol{x} - \\boldsymbol{x}_{i}}{h_{n}} \\right) \\right] \\\\ \\\\\n",
    "        &= \\int \\frac{1}{V_{n}} \\varphi \\left( \\frac{\\boldsymbol{x} - \\boldsymbol{v}}{h_{n}} \\right) p(\\boldsymbol{v}) d\\boldsymbol{v} \\\\ \\\\\n",
    "        &= \\int \\delta_{n}(\\boldsymbol{x} - \\boldsymbol{v}) p(\\boldsymbol{v}) d\\boldsymbol{v} = (\\delta_{n} \\ast p)(\\boldsymbol{x})\n",
    "        \\end{align*}\n",
    "        $$\n",
    "        * 在样本数量趋于无穷时，估计值的期望需要满足\n",
    "        $$\n",
    "        \\begin{gather*}\n",
    "        \\lim_{n \\to \\infty} \\delta_{n}(\\boldsymbol{x} - \\boldsymbol{v}) = \\delta(\\boldsymbol{x} - \\boldsymbol{v}) \\\\\n",
    "        \\Downarrow \\\\\n",
    "        \\begin{align*}\n",
    "        \\lim_{n \\to \\infty} \\mathcal{E} p_{n}(\\boldsymbol{x}) &= \n",
    "        \\lim_{n \\to \\infty} \\int \\delta_{n}(\\boldsymbol{x} - \\boldsymbol{v}) p(\\boldsymbol{v}) d\\boldsymbol{v} \\\\ \\\\\n",
    "        &= \\int \\lim_{n \\to \\infty} \\delta_{n}(\\boldsymbol{x} - \\boldsymbol{v}) p(\\boldsymbol{v}) d\\boldsymbol{v} \\\\ \\\\\n",
    "        &= \\int \\delta(\\boldsymbol{x} - \\boldsymbol{v}) p(\\boldsymbol{v}) d\\boldsymbol{v} = p(\\boldsymbol{x})\n",
    "        \\end{align*}\n",
    "        \\end{gather*}\n",
    "        $$\n",
    "        * 即需要满足条件\n",
    "        $$\n",
    "        \\begin{gather*}\n",
    "        \\lim_{n \\to \\infty} V_{n} = 0 \\\\ \\\\\n",
    "        \\lim_{||\\boldsymbol{u}|| \\to \\infty} \\varphi(\\boldsymbol{u}) \\prod_{i = 1}^{d} u_{i} = 0\n",
    "        \\end{gather*}\n",
    "        $$\n",
    "        * 在上述条件的基础上，可以证明影响因子的极限满足狄拉克函数$\\delta(\\boldsymbol{x} - \\boldsymbol{v})$的性质\n",
    "        $$\n",
    "        \\begin{gather*}\n",
    "        \\int_{\\mathbb{R}^d} \\delta_{n}(\\boldsymbol{x} - \\boldsymbol{v}) d\\boldsymbol{x} = \\int_{\\mathbb{R}^d} \\varphi(\\boldsymbol{u}) d\\boldsymbol{u} = 1 \\\\ \\\\\n",
    "        \\begin{align*}\n",
    "        \\lim_{n \\to \\infty} \\delta_{n}(\\boldsymbol{x} - \\boldsymbol{v}) &= \\lim_{n \\to \\infty} \\frac{1}{V_{n}} \n",
    "        \\varphi(\\frac{\\boldsymbol{x} - \\boldsymbol{v}}{h_{n}}) \\\\ \\\\\n",
    "        &= \\lim_{n \\to \\infty} \\frac{1}{h_{n}^{d}} \\varphi(\\frac{x_{1} - v_{1}}{h_{n}},\\ \\cdots,\\ \\frac{x_{d} - v_{d}}{h_{n}}) \\\\ \\\\\n",
    "        &\\overset{\\boldsymbol{x} \\ne \\boldsymbol{v}}{\\longrightarrow} \n",
    "        \\lim_{||\\boldsymbol{u}|| \\to \\infty} \\varphi(\\boldsymbol{u}) \\prod_{i = 1}^{d} u_{i} \\bigg/ \\prod_{i = 1}^{d} (x_{i} - v_{i}) = 0\n",
    "        \\end{align*}\n",
    "        \\end{gather*}\n",
    "        $$\n",
    "        * 再考虑估计概率密度在训练集上的方差\n",
    "        $$\n",
    "        \\begin{align*}\n",
    "        \\mathcal{D} p_{n}(\\boldsymbol{x}) &= \\mathcal{E} p_{n}^{2} (\\mathcal{x}) - \\mathcal{E}^{2} p_{n}(\\boldsymbol{x}) \\\\ \\\\\n",
    "        &\\le \\sum_{i = 1}^{n} \\mathcal{E} \\left[ \\frac{1}{n^{2} V_{n}^{2}} \\varphi^{2} \n",
    "        \\left( \\frac{\\boldsymbol{x} - \\boldsymbol{x}_{i}}{h_{n}} \\right) \\right] \\\\ \\\\\n",
    "        &= \\frac{1}{nV_{n}} \\int \\frac{1}{V_{n}} \\varphi^{2} \\left( \\frac{\\boldsymbol{x} - \\boldsymbol{v}}{h_{n}} \\right) d\\boldsymbol{v} \\\\ \\\\\n",
    "        &\\le \\frac{\\max \\varphi(\\cdot) \\mathcal{E} p_{n}(\\boldsymbol{x})}{nV_{n}}\n",
    "        \\end{align*}\n",
    "        $$\n",
    "        * 样本数量趋于无穷时，估计值的方差需要满足\n",
    "        $$\n",
    "        \\lim_{n \\to \\infty} \\mathcal{D} p_{n}(\\boldsymbol{x}) \\le\n",
    "        \\lim_{n \\to \\infty} \\frac{\\max \\varphi(\\cdot) \\mathcal{E} p_{n}(\\boldsymbol{x})}{nV_{n}}\n",
    "        = \\frac{\\max \\varphi(\\cdot) p(\\mathcal{x})}{\\lim_{n \\to \\infty} nV_{n}} = 0\n",
    "        $$\n",
    "        * 即需要满足条件\n",
    "        $$\n",
    "        \\begin{gather*}\n",
    "        \\max \\varphi(\\cdot) < \\infty \\\\ \\\\\n",
    "        \\lim_{n \\to \\infty} nV_{n} = \\infty\n",
    "        \\end{gather*}\n",
    "        $$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $k_{n}$近邻\n",
    "<br /><br />\n",
    "    * 固定一个合法的频数$k_{n}$序列，以$\\boldsymbol{x}$为中心让体积不断扩张直至包含到$k_{n}$个样本点，估计概率密度\n",
    "    $$\n",
    "    p_{n}(\\boldsymbol{x}) = \\frac{k_{n} / n}{V_{n}}\n",
    "    $$\n",
    "    * 与$\\mathrm{Parzen}$窗方法不同的是，$k_{n}$近邻可以动态调整估计窗口大小，同时保证窗口内总是包含样本点\n",
    "    <br /><br />\n",
    "    * 但$k_{n}$近邻在一阶微分上并不连续，会产生崎岖的尖峰，同时$k_{n}$近邻不能保证估计概率密度的归一性\n",
    "    $$\n",
    "    \\int_{\\mathbb{R}^{d}} p_{n}(\\boldsymbol{x}) d\\boldsymbol{x} \\overset{?}{=} 1\n",
    "    $$\n",
    "    * $k_{n}$近邻可以直接估计后验概率\n",
    "    $$\n",
    "    \\begin{gather*}\n",
    "    p_{n}(\\boldsymbol{x},\\ \\omega_{i}) = \\frac{k_{i} / n}{V_{n}} \\\\ \\\\\n",
    "    p_{n}(\\boldsymbol{x}) = \\frac{k_{n} / n}{V_{n}} \\\\ \\\\\n",
    "    p_{n}(\\omega_{i} \\mid \\boldsymbol{x}) = \\frac{k_{i}}{k_{n}}\n",
    "    \\end{gather*}\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 最近邻规则\n",
    "<br /><br />\n",
    "    * 将未见样本$\\boldsymbol{x}$的类别预测为训练集$D_{n}$中与它距离最近的样本点$\\tilde{\\boldsymbol{x}}$的类别\n",
    "    $$\n",
    "    \\tilde{\\boldsymbol{x}} = arg \\min_{\\boldsymbol{x}_{i}} ||\\boldsymbol{x}_{i} - \\boldsymbol{x}||\n",
    "    $$\n",
    "    * 在样本数量趋于无穷时，可以认为最近邻样本点$\\tilde{\\boldsymbol{x}}$与未见样本$\\boldsymbol{x}$足够近\n",
    "    $$\n",
    "    ||\\tilde{\\boldsymbol{x}} - \\boldsymbol{x}|| \\approx 0 \\longrightarrow \n",
    "    p(\\omega_{i} \\mid \\tilde{\\boldsymbol{x}_{i}}) \\approx p(\\omega_{i} \\mid \\boldsymbol{x}_{i})\n",
    "    $$\n",
    "    * 为了衡量最近邻规则的性能，考虑样本数量趋于无穷时的平均误差率$p(error)$\n",
    "    $$\n",
    "    p(error) = \\lim_{n \\to \\infty} \\mathcal{E} p_{n}(error \\mid \\boldsymbol{x}) =\n",
    "    \\lim_{n \\to \\infty} \\int p_{n}(error \\mid \\boldsymbol{x}) p(\\boldsymbol{x}) d\\boldsymbol{x}\n",
    "    $$\n",
    "    * 理论最优的贝叶斯分类器的平均误差率$\\wp(error)$\n",
    "    $$\n",
    "    \\begin{gather*}\n",
    "    \\wp(error) = \\mathcal{E} \\wp(error \\mid \\boldsymbol{x}) = \\int \\wp(error \\mid \\boldsymbol{x}) p(\\boldsymbol{x}) d\\boldsymbol{x} \\\\ \\\\\n",
    "    \\wp(error \\mid \\boldsymbol{x}) = 1 - \\max_{i} p(\\omega_{i} \\mid \\boldsymbol{x})\n",
    "    \\end{gather*}\n",
    "    $$\n",
    "    * 对于最近邻规则，随机训练集$D_{n}$对应着一个未见样本$\\boldsymbol{x}$的随机最近邻向量$\\tilde{\\boldsymbol{x}}$，条件误差率$p_{n}(error \\mid \\boldsymbol{x})$可以写作\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    p_{n}(error \\mid \\boldsymbol{x}) &= \\mathcal{E} \\bigg( p_{n}(error \\mid \\boldsymbol{x},\\ \\tilde{\\boldsymbol{x}})\\ \\bigg|\\ \\boldsymbol{x} \\bigg) \\\\ \\\\\n",
    "    &= \\int p_{n}(error \\mid \\boldsymbol{x},\\ \\tilde{\\boldsymbol{x}}) p_{n}(\\tilde{\\boldsymbol{x}} \\mid \\boldsymbol{x}) d\\tilde{\\boldsymbol{x}}\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    * 考虑一个样本$\\tilde{\\boldsymbol{x}}$落在未见样本$\\boldsymbol{x}$为中心的超球体$\\mathcal{S}$中的概率\n",
    "    $$\n",
    "    P_{n} = \\int_{\\mathcal{S}} p_{n}(\\tilde{\\boldsymbol{x}} \\mid \\boldsymbol{x}) d\\tilde{\\boldsymbol{x}}\n",
    "    $$\n",
    "    * 令样本数量趋于无穷，同时令超球体的半径趋于零，所有样本均落在超球体外部的概率\n",
    "    $$\n",
    "    \\lim_{n \\to \\infty} (1 - P_{n})^{n} = 0\n",
    "    $$\n",
    "    * 也就是说，最近邻向量的后验概率分布在样本数量趋于无穷时，满足狄拉克函数$\\delta(\\tilde{\\boldsymbol{x}} - \\boldsymbol{x})$的性质\n",
    "    $$\n",
    "    \\begin{gather*}\n",
    "    \\int p_{n}(\\tilde{\\boldsymbol{x}} \\mid \\boldsymbol{x}) d\\tilde{\\boldsymbol{x}} = 1 \\\\ \\\\\n",
    "    \\lim_{n \\to \\infty} p_{n}(\\tilde{\\boldsymbol{x}} \\mid \\boldsymbol{x}) \\overset{\\tilde{\\boldsymbol{x}} \\ne \\boldsymbol{x}}{\\longrightarrow} 0\n",
    "    \\end{gather*}\n",
    "    $$\n",
    "    * 由于训练集和未见样本相互独立且均服从分布$p(\\omega_{i},\\ \\boldsymbol{x})$和$p(\\boldsymbol{x})$，有\n",
    "    $$\n",
    "    p(\\omega_{i},\\ \\omega_{j} \\mid \\boldsymbol{x},\\ \\tilde{\\boldsymbol{x}}) = \n",
    "    \\frac{p(\\omega_{i},\\ \\boldsymbol{x};\\ \\omega_{j},\\ \\tilde{\\boldsymbol{x}})}{p(\\boldsymbol{x},\\ \\tilde{\\boldsymbol{x}})} =\n",
    "    \\frac{p(\\omega_{i},\\ \\boldsymbol{x}) p(\\omega_{j},\\ \\tilde{\\boldsymbol{x}})}{p(\\boldsymbol{x}) p(\\tilde{\\boldsymbol{x}})} =\n",
    "    p(\\omega_{i} \\mid \\boldsymbol{x}) p(\\omega_{j} \\mid \\tilde{\\boldsymbol{x}})\n",
    "    $$\n",
    "    * 根据上式，条件误差率$p_{n}(error \\mid \\boldsymbol{x},\\ \\tilde{\\boldsymbol{x}})$可以写为\n",
    "    $$\n",
    "    p_{n}(error \\mid \\boldsymbol{x},\\ \\tilde{\\boldsymbol{x}}) = 1 - \\sum_{i = 1}^{c} \n",
    "    p(\\omega_{i},\\ \\omega_{i} \\mid \\boldsymbol{x},\\ \\tilde{\\boldsymbol{x}})\n",
    "    = 1 - \\sum_{i = 1}^{c} p(\\omega_{i} \\mid \\boldsymbol{x}) p(\\omega_{i} \\mid \\tilde{\\boldsymbol{x}})\n",
    "    $$\n",
    "    * 由此可得，样本数量趋于无穷时的条件误差率$p_{n}(error \\mid \\boldsymbol{x})$\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    \\lim_{n \\to \\infty} p_{n}(error \\mid \\boldsymbol{x}) &= \\lim_{n \\to \\infty} \\int p_{n}(error \\mid \\boldsymbol{x},\\ \\tilde{\\boldsymbol{x}}) \n",
    "    p_{n}(\\tilde{\\boldsymbol{x}} \\mid \\boldsymbol{x}) d\\tilde{\\boldsymbol{x}} \\\\ \\\\\n",
    "    &= \\int \\left[ 1 - \\sum_{i = 1}^{c} p(\\omega_{i} \\mid \\boldsymbol{x}) p(\\omega_{i} \\mid \\tilde{\\boldsymbol{x}}) \\right]\n",
    "    \\delta(\\tilde{\\boldsymbol{x}} - \\boldsymbol{x}) d\\tilde{\\boldsymbol{x}} \\\\ \\\\\n",
    "    &= 1 - \\sum_{i = 1}^{c} p^{2}(\\omega_{i} \\mid \\boldsymbol{x})\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    * 进而可得，样本数量趋于无穷时的平均误差率\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    p(error) &= \\lim_{n \\to \\infty} \\int p_{n}(error \\mid \\boldsymbol{x}) p(\\boldsymbol{x}) d\\boldsymbol{x} \\\\ \\\\\n",
    "    &= \\int \\left[ 1 - \\sum_{i = 1}^{c} p^{2}(\\omega_{i} \\mid \\boldsymbol{x}) \\right] p(\\boldsymbol{x}) d\\boldsymbol{x}\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    * 为了与贝叶斯误差$\\wp(error)$作比较，考虑在贝叶斯误差固定时，寻找最近邻误差的误差界\n",
    "    <br /><br /> \n",
    "        * 贝叶斯误差固定等价于最大后验概率$p(\\omega_{m} \\mid \\boldsymbol{x}) = \\max_{i} p(\\omega_{i} \\mid \\boldsymbol{x})$固定，首先有\n",
    "        $$\n",
    "        \\sum_{i = 1}^{c} p^{2}(\\omega_{i} \\mid \\boldsymbol{x}) = p^{2}(\\omega_{m} \\mid \\boldsymbol{x}) + \\sum_{i \\ne m} p^{2}(\\omega_{i} \\mid \\boldsymbol{x})\n",
    "        $$\n",
    "        * 在上述条件的约束下寻找最近邻误差的上界\n",
    "        $$\n",
    "        \\begin{gather*}\n",
    "        \\max p(error) \\Longleftrightarrow \\min \\sum_{i \\ne m} p^{2}(\\omega_{i} \\mid \\boldsymbol{x}) \\\\ \\\\\n",
    "        s.t.\\quad p(\\omega_{i} \\mid \\boldsymbol{x}) \\ge 0 \\quad \n",
    "        \\sum_{i \\ne m} p(\\omega_{i} \\mid \\boldsymbol{x}) = 1 - p(\\omega_{m} \\mid \\boldsymbol{x}) = \\wp(error \\mid \\boldsymbol{x})\n",
    "        \\end{gather*}\n",
    "        $$\n",
    "        * 根据$\\mathrm{Cauchy-Schwarz}$不等式\n",
    "        $$\n",
    "        \\sum_{i \\ne m} p^{2}(\\omega_{i} \\mid \\boldsymbol{x}) \\ge \\frac{1}{c - 1} \\left[ \\sum_{i \\ne m} p(\\omega_{i} \\mid \\boldsymbol{x}) \\right]^{2}\n",
    "        = \\frac{1}{c - 1} \\wp^{2}(error \\mid \\boldsymbol{x})\n",
    "        $$\n",
    "        * 上式等号当且仅当\n",
    "        $$\n",
    "        p(\\omega_{i} \\mid \\boldsymbol{x}) = \\frac{\\wp(error \\mid \\boldsymbol{x})}{c - 1},\\quad i \\ne m\n",
    "        $$\n",
    "        * 进而可得\n",
    "        $$\n",
    "        1 - \\sum_{i = 1}^{c} p^{2}(\\omega_{i} \\mid \\boldsymbol{x}) \\le 2\\wp(error \\mid \\boldsymbol{x}) - \\frac{c}{c - 1} \\wp^{2}(error \\mid \\boldsymbol{x})\n",
    "        $$\n",
    "        * 同时考虑$\\wp^{2}(error \\mid \\boldsymbol{x})$和$\\wp(error)$之间的关系\n",
    "        $$\n",
    "        \\begin{align*}\n",
    "        \\mathcal{D} \\wp(error \\mid \\boldsymbol{x}) &= \\mathcal{E} \\wp^{2}(error \\mid \\boldsymbol{x}) - \\wp^{2}(error) \\\\ \\\\\n",
    "        &= \\int \\wp^{2}(error \\mid \\boldsymbol{x}) p(\\boldsymbol{x}) d\\boldsymbol{x} - \\wp^{2}(error) \\ge 0\n",
    "        \\end{align*}\n",
    "        $$\n",
    "        * 代入到最近邻误差中即可得到\n",
    "        $$\n",
    "        p(error) = \\int \\left[ 1 - \\sum_{i = 1}^{c} p^{2}(\\omega_{i} \\mid \\boldsymbol{x}) \\right] p(\\boldsymbol{x}) d\\boldsymbol{x}\n",
    "        \\le 2\\wp(error) - \\frac{c}{c - 1} \\wp^{2}(error)\n",
    "        $$\n",
    "        * 最终的最近邻误差范围\n",
    "        $$\n",
    "        \\wp(error) \\le p(error) \\le \\left( 2 - \\frac{c}{c - 1} \\wp(error) \\right) \\wp(error)\n",
    "        $$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
